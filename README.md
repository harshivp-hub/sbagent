# SmalBlu LLM Agent

A minimal, working LLM-powered service that analyzes cloud infrastructure data and outputs cost-optimization recommendations. Built in Python with modular, extensible design and schema validation.

---

## ðŸ“‚ Project Structure

```
smalblu-agent/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ base_agent.py          # Wraps the OpenAI chat API
â”‚   â”œâ”€â”€ compute_agent.py       # Implements compute-focused optimization + fallback
â”‚   â””â”€â”€ storage_agent.py       # Stub for future storage logic
â”œâ”€â”€ orchestrator/
â”‚   â””â”€â”€ orchestrator.py        # Coordinates one or more agents
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ input_schema.py        # Pydantic models for input validation
â”‚   â””â”€â”€ output_schema.py       # Pydantic models for output + JSON serialization
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ fixtures/              # Sample JSON inputs (small + large)
â”‚   â””â”€â”€ test_compute_agent.py  # Pytest tests for all scenarios
â”œâ”€â”€ .env.example               # Environment variable template
â”œâ”€â”€ main.py                    # Entrypoint: loads data, runs orchestrator, writes output
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # This file
```

---

## ðŸ”§ Setup

1. **Clone the repo & enter directory**

   ```bash
   git clone <repo-url>
   cd smalblu-agent
   ```

2. **Copy & edit environment file**

   ```bash
   cp .env.example .env
   # Open .env and set:
   # OPENAI_API_KEY=sk-...
   # OPENAI_MODEL=gpt-4-turbo
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

---

## ðŸš€ Usage

Run the agent on any JSON fixture or custom input:

```bash
python main.py tests/fixtures/over_provisioned.json outputs/over_output.json
```

* **Input**: Path to a JSON file matching the `InfrastructureData` schema.
* **Output**: Path to write the `OptimizationResult` JSON. Folders are auto-created.

---

## ðŸ§ª Testing

Ensure all scenarios pass:

```bash
pytest
```

* Covers **over-provisioned**, **under-provisioned**, and **mixed** workloads (small and large fixtures).

---

## ðŸ”„ Extensibility

* **Add new agents**:

  1. Create `agents/your_agent.py` subclassing `BaseAgent`.
  2. Register in `orchestrator/orchestrator.py`.
* **Human-in-Loop**:

  * Inspect `Recommendation.confidence` and route low-confidence output to a review UI.
* **Advanced features**:

  * Vector-store context injection (FAISS, Chroma)
  * Caching / rate-limit management
  * Integration with infra pipelines (Terraform, Jenkins, Slack notifications)

---

## ðŸ”® Future Enhancements

* Implement **StorageAgent** and **DatabaseAgent**
* Add **rule-based validators** before/after LLM calls
* Introduce **automatic prompt tuning** from human feedback
* Integrate **monitoring & logging** (e.g., Prometheus, Sentry)

---

**Enjoy optimizing your cloud infrastructure with LLMs!**
